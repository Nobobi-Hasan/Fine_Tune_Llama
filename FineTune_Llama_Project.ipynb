{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7CZPyjUQoezqEr4k+NMgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc553e61f3f646bbb07e283015153519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1803ca8d0d6466ead2f97eedbed3cf8",
              "IPY_MODEL_6e2f30dc29984ca8be6e5c9ed717d0bc",
              "IPY_MODEL_a98d23652e1b4bf3a18aa1a02cf12534"
            ],
            "layout": "IPY_MODEL_0b3f8eec26634792857e2468cda33af1"
          }
        },
        "e1803ca8d0d6466ead2f97eedbed3cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae11800ddca4802b6b28fdf0c68f7ef",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e4c9b9be2441b0bec7d2486d9ba523",
            "value": "Map: 100%"
          }
        },
        "6e2f30dc29984ca8be6e5c9ed717d0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788de093a4da4da98b9518b673a99b65",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b908a568101f44aba10fc8834b03fb37",
            "value": 1000
          }
        },
        "a98d23652e1b4bf3a18aa1a02cf12534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9d3d3a5b4042c0914ebc97feb31b39",
            "placeholder": "​",
            "style": "IPY_MODEL_b3e1bb89d2d442e3a1b180c00821f6d5",
            "value": " 1000/1000 [00:00&lt;00:00, 7655.75 examples/s]"
          }
        },
        "0b3f8eec26634792857e2468cda33af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae11800ddca4802b6b28fdf0c68f7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e4c9b9be2441b0bec7d2486d9ba523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "788de093a4da4da98b9518b673a99b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b908a568101f44aba10fc8834b03fb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af9d3d3a5b4042c0914ebc97feb31b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e1bb89d2d442e3a1b180c00821f6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "420aa20a66ff438183ba9f951d975f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1881fdde96e947bbb9acc96bf9640d56",
              "IPY_MODEL_258c173589d5446c88cbbbc138a5547b",
              "IPY_MODEL_02a5b5ba92f345e6b89c399d431c7803"
            ],
            "layout": "IPY_MODEL_f6389900233f4072856b776828199aee"
          }
        },
        "1881fdde96e947bbb9acc96bf9640d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d739726c169449295624a3bac536d13",
            "placeholder": "​",
            "style": "IPY_MODEL_0400930ad2a444dda17b63143499e780",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "258c173589d5446c88cbbbc138a5547b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51fe3a35b624b73baa9a5b13da84edc",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e531bcd973804ca6897240d291ba74e0",
            "value": 1000
          }
        },
        "02a5b5ba92f345e6b89c399d431c7803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b60355747d4fb495679faeb3a4791f",
            "placeholder": "​",
            "style": "IPY_MODEL_36d7cf37fb0d43d0b170a6e8fe9c97d6",
            "value": " 1000/1000 [00:00&lt;00:00, 34268.59 examples/s]"
          }
        },
        "f6389900233f4072856b776828199aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d739726c169449295624a3bac536d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0400930ad2a444dda17b63143499e780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51fe3a35b624b73baa9a5b13da84edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e531bcd973804ca6897240d291ba74e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29b60355747d4fb495679faeb3a4791f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d7cf37fb0d43d0b170a6e8fe9c97d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nobobi-Hasan/Fine_Tune_Llama/blob/main/FineTune_Llama_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tune with Llama Project**"
      ],
      "metadata": {
        "id": "98hJiOFjgu6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5s2GFR90YTKy",
        "outputId": "f56a8509-2a5a-4941-ff2a-1057ee11fe08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtune in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: torchdata==0.11.0 in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.11.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from torchtune) (4.0.0)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.35.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.6.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.3.13)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.2.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.11.0)\n",
            "Requirement already satisfied: blobfile>=2 in /usr/local/lib/python3.12/dist-packages (from torchtune) (3.1.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtune) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtune) (4.67.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from torchtune) (2.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.12/dist-packages (from torchtune) (11.3.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.32.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.8.0+cu126)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (3.23.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (5.4.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (1.1.10)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (0.1.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->torchtune) (4.9.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata==0.11.0->torchtune) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->torchtune) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2->torchdata==0.11.0->torchtune) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2->torchdata==0.11.0->torchtune) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tune ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0vfMlHxPVRFm",
        "outputId": "bff1ac2e-167b-4c7e-c8f2-d6a0e09b72bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RECIPE                                   CONFIG                                  \n",
            "full_finetune_single_device              llama2/7B_full_low_memory               \n",
            "                                         code_llama2/7B_full_low_memory          \n",
            "                                         llama3/8B_full_single_device            \n",
            "                                         llama3_1/8B_full_single_device          \n",
            "                                         llama3_2/1B_full_single_device          \n",
            "                                         llama3_2/3B_full_single_device          \n",
            "                                         mistral/7B_full_low_memory              \n",
            "                                         phi3/mini_full_low_memory               \n",
            "                                         phi4/14B_full_low_memory                \n",
            "                                         qwen2/7B_full_single_device             \n",
            "                                         qwen2/0.5B_full_single_device           \n",
            "                                         qwen2/1.5B_full_single_device           \n",
            "                                         qwen2_5/0.5B_full_single_device         \n",
            "                                         qwen2_5/1.5B_full_single_device         \n",
            "                                         qwen2_5/3B_full_single_device           \n",
            "                                         qwen2_5/7B_full_single_device           \n",
            "                                         llama3_2_vision/11B_full_single_device  \n",
            "full_finetune_distributed                llama2/7B_full                          \n",
            "                                         llama2/13B_full                         \n",
            "                                         llama3/8B_full                          \n",
            "                                         llama3_1/8B_full                        \n",
            "                                         llama3_2/1B_full                        \n",
            "                                         llama3_2/3B_full                        \n",
            "                                         llama3/70B_full                         \n",
            "                                         llama3_1/70B_full                       \n",
            "                                         llama3_3/70B_full                       \n",
            "                                         llama3_3/70B_full_multinode             \n",
            "                                         mistral/7B_full                         \n",
            "                                         gemma/2B_full                           \n",
            "                                         gemma/7B_full                           \n",
            "                                         gemma2/2B_full                          \n",
            "                                         gemma2/9B_full                          \n",
            "                                         gemma2/27B_full                         \n",
            "                                         phi3/mini_full                          \n",
            "                                         phi4/14B_full                           \n",
            "                                         qwen2/7B_full                           \n",
            "                                         qwen2/0.5B_full                         \n",
            "                                         qwen2/1.5B_full                         \n",
            "                                         qwen2_5/0.5B_full                       \n",
            "                                         qwen2_5/1.5B_full                       \n",
            "                                         qwen2_5/3B_full                         \n",
            "                                         qwen2_5/7B_full                         \n",
            "                                         llama3_2_vision/11B_full                \n",
            "                                         llama3_2_vision/90B_full                \n",
            "lora_finetune_single_device              llama2/7B_lora_single_device            \n",
            "                                         llama2/7B_qlora_single_device           \n",
            "                                         code_llama2/7B_lora_single_device       \n",
            "                                         code_llama2/7B_qlora_single_device      \n",
            "                                         llama3/8B_lora_single_device            \n",
            "                                         llama3_1/8B_lora_single_device          \n",
            "                                         llama3/8B_qlora_single_device           \n",
            "                                         llama3_2/1B_lora_single_device          \n",
            "                                         llama3_2/3B_lora_single_device          \n",
            "                                         llama3/8B_dora_single_device            \n",
            "                                         llama3/8B_qdora_single_device           \n",
            "                                         llama3_1/8B_qlora_single_device         \n",
            "                                         llama3_2/1B_qlora_single_device         \n",
            "                                         llama3_2/3B_qlora_single_device         \n",
            "                                         llama2/13B_qlora_single_device          \n",
            "                                         mistral/7B_lora_single_device           \n",
            "                                         mistral/7B_qlora_single_device          \n",
            "                                         gemma/2B_lora_single_device             \n",
            "                                         gemma/2B_qlora_single_device            \n",
            "                                         gemma/7B_lora_single_device             \n",
            "                                         gemma/7B_qlora_single_device            \n",
            "                                         gemma2/2B_lora_single_device            \n",
            "                                         gemma2/2B_qlora_single_device           \n",
            "                                         gemma2/9B_lora_single_device            \n",
            "                                         gemma2/9B_qlora_single_device           \n",
            "                                         gemma2/27B_lora_single_device           \n",
            "                                         gemma2/27B_qlora_single_device          \n",
            "                                         phi3/mini_lora_single_device            \n",
            "                                         phi3/mini_qlora_single_device           \n",
            "                                         phi4/14B_lora_single_device             \n",
            "                                         phi4/14B_qlora_single_device            \n",
            "                                         qwen2/7B_lora_single_device             \n",
            "                                         qwen2/0.5B_lora_single_device           \n",
            "                                         qwen2/1.5B_lora_single_device           \n",
            "                                         qwen2_5/0.5B_lora_single_device         \n",
            "                                         qwen2_5/1.5B_lora_single_device         \n",
            "                                         qwen2_5/3B_lora_single_device           \n",
            "                                         qwen2_5/7B_lora_single_device           \n",
            "                                         qwen2_5/14B_lora_single_device          \n",
            "                                         llama3_2_vision/11B_lora_single_device  \n",
            "                                         llama3_2_vision/11B_qlora_single_device \n",
            "lora_dpo_single_device                   llama2/7B_lora_dpo_single_device        \n",
            "                                         llama3_1/8B_lora_dpo_single_device      \n",
            "lora_dpo_distributed                     llama2/7B_lora_dpo                      \n",
            "                                         llama3_1/8B_lora_dpo                    \n",
            "full_dpo_distributed                     llama3_1/8B_full_dpo                    \n",
            "ppo_full_finetune_single_device          mistral/7B_full_ppo_low_memory          \n",
            "lora_finetune_distributed                llama2/7B_lora                          \n",
            "                                         llama2/13B_lora                         \n",
            "                                         llama2/70B_lora                         \n",
            "                                         llama2/7B_qlora                         \n",
            "                                         llama2/70B_qlora                        \n",
            "                                         llama3/8B_dora                          \n",
            "                                         llama3/70B_lora                         \n",
            "                                         llama3_1/70B_lora                       \n",
            "                                         llama3_3/70B_lora                       \n",
            "                                         llama3_3/70B_qlora                      \n",
            "                                         llama3/8B_lora                          \n",
            "                                         llama3_1/8B_lora                        \n",
            "                                         llama3_2/1B_lora                        \n",
            "                                         llama3_2/3B_lora                        \n",
            "                                         llama3_1/405B_qlora                     \n",
            "                                         mistral/7B_lora                         \n",
            "                                         gemma/2B_lora                           \n",
            "                                         gemma/7B_lora                           \n",
            "                                         gemma2/2B_lora                          \n",
            "                                         gemma2/9B_lora                          \n",
            "                                         gemma2/27B_lora                         \n",
            "                                         phi3/mini_lora                          \n",
            "                                         phi4/14B_lora                           \n",
            "                                         qwen2/7B_lora                           \n",
            "                                         qwen2/0.5B_lora                         \n",
            "                                         qwen2/1.5B_lora                         \n",
            "                                         qwen2_5/0.5B_lora                       \n",
            "                                         qwen2_5/1.5B_lora                       \n",
            "                                         qwen2_5/3B_lora                         \n",
            "                                         qwen2_5/7B_lora                         \n",
            "                                         qwen2_5/32B_lora                        \n",
            "                                         qwen2_5/72B_lora                        \n",
            "                                         llama3_2_vision/11B_lora                \n",
            "                                         llama3_2_vision/11B_qlora               \n",
            "                                         llama3_2_vision/90B_lora                \n",
            "                                         llama3_2_vision/90B_qlora               \n",
            "dev/lora_finetune_distributed_multi_dataset dev/11B_lora_multi_dataset              \n",
            "generate                                 generation                              \n",
            "dev/generate_v2                          llama2/generation_v2                    \n",
            "                                         llama3_2_vision/11B_generation_v2       \n",
            "dev/generate_v2_distributed              llama3/70B_generation_distributed       \n",
            "                                         llama3_1/70B_generation_distributed     \n",
            "                                         llama3_3/70B_generation_distributed     \n",
            "dev/early_exit_finetune_distributed      llama2/7B_full_early_exit               \n",
            "eleuther_eval                            eleuther_evaluation                     \n",
            "                                         llama3_2_vision/11B_evaluation          \n",
            "                                         qwen2/evaluation                        \n",
            "                                         qwen2_5/evaluation                      \n",
            "                                         gemma/evaluation                        \n",
            "                                         phi4/evaluation                         \n",
            "                                         phi3/evaluation                         \n",
            "                                         mistral/evaluation                      \n",
            "                                         llama3_2/evaluation                     \n",
            "                                         code_llama2/evaluation                  \n",
            "quantize                                 quantization                            \n",
            "qat_distributed                          llama2/7B_qat_full                      \n",
            "                                         llama3/8B_qat_full                      \n",
            "qat_lora_finetune_distributed            llama3/8B_qat_lora                      \n",
            "                                         llama3_1/8B_qat_lora                    \n",
            "                                         llama3_2/1B_qat_lora                    \n",
            "                                         llama3_2/3B_qat_lora                    \n",
            "knowledge_distillation_single_device     qwen2/1.5_to_0.5B_KD_lora_single_device \n",
            "                                         llama3_2/8B_to_1B_KD_lora_single_device \n",
            "knowledge_distillation_distributed       qwen2/1.5_to_0.5B_KD_lora_distributed   \n",
            "                                         llama3_2/8B_to_1B_KD_lora_distributed   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli download meta-llama/Llama-3.2-1B-Instruct --local-dir /tmp/Llama-3.2-1B-Instruct"
      ],
      "metadata": {
        "id": "lwnGThI7dlaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !torchtune run full_finetune_single_device --config llama3_2/1B_full_single_device device=cpu epochs=1\n",
        "!tune run full_finetune_single_device --config llama3_2/1B_full_single_device device=cpu epochs=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47uQ_kMaVd0l",
        "outputId": "b2b57639-b3ae-40a2-e21e-2f1407034e60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:\n",
            "\n",
            "batch_size: 4\n",
            "checkpointer:\n",
            "  _component_: torchtune.training.FullModelHFCheckpointer\n",
            "  checkpoint_dir: /tmp/Llama-3.2-1B-Instruct/\n",
            "  checkpoint_files:\n",
            "  - model.safetensors\n",
            "  model_type: LLAMA3_2\n",
            "  output_dir: /tmp/torchtune/llama3_2_1B/full_single_device\n",
            "  recipe_checkpoint: null\n",
            "clip_grad_norm: null\n",
            "compile: false\n",
            "dataset:\n",
            "  _component_: torchtune.datasets.alpaca_dataset\n",
            "  packed: false\n",
            "device: cpu\n",
            "dtype: bf16\n",
            "enable_activation_checkpointing: false\n",
            "enable_activation_offloading: false\n",
            "epochs: 1\n",
            "gradient_accumulation_steps: 1\n",
            "log_every_n_steps: 1\n",
            "log_peak_memory_stats: true\n",
            "loss:\n",
            "  _component_: torchtune.modules.loss.CEWithChunkedOutputLoss\n",
            "max_steps_per_epoch: null\n",
            "metric_logger:\n",
            "  _component_: torchtune.training.metric_logging.DiskLogger\n",
            "  log_dir: /tmp/torchtune/llama3_2_1B/full_single_device/logs\n",
            "model:\n",
            "  _component_: torchtune.models.llama3_2.llama3_2_1b\n",
            "optimizer:\n",
            "  _component_: bitsandbytes.optim.PagedAdamW8bit\n",
            "  lr: 2.0e-05\n",
            "optimizer_in_bwd: true\n",
            "output_dir: /tmp/torchtune/llama3_2_1B/full_single_device\n",
            "profiler:\n",
            "  _component_: torchtune.training.setup_torch_profiler\n",
            "  active_steps: 2\n",
            "  cpu: true\n",
            "  cuda: true\n",
            "  enabled: false\n",
            "  num_cycles: 1\n",
            "  output_dir: /tmp/torchtune/llama3_2_1B/full_single_device/profiling_outputs\n",
            "  profile_memory: false\n",
            "  record_shapes: true\n",
            "  wait_steps: 5\n",
            "  warmup_steps: 3\n",
            "  with_flops: false\n",
            "  with_stack: false\n",
            "resume_from_checkpoint: false\n",
            "seed: null\n",
            "shuffle: true\n",
            "tokenizer:\n",
            "  _component_: torchtune.models.llama3.llama3_tokenizer\n",
            "  max_seq_len: null\n",
            "  path: /tmp/Llama-3.2-1B-Instruct/original/tokenizer.model\n",
            "\n",
            "INFO:torchtune.utils._logging:log_peak_memory_stats was set to True, however, training uses cpu. Setting log_peak_memory_stats=False.\n",
            "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 3005221510. Local seed is seed + rank = 3005221510 + 0\n",
            "Writing logs to /tmp/torchtune/llama3_2_1B/full_single_device/logs/log_1758649773.txt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tune\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/_cli/tune.py\", line 52, in main\n",
            "    parser.run(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/_cli/tune.py\", line 46, in run\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/_cli/run.py\", line 214, in _run_cmd\n",
            "    self._run_single_device(args, is_builtin=is_builtin)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/_cli/run.py\", line 108, in _run_single_device\n",
            "    runpy.run_path(str(args.recipe), run_name=\"__main__\")\n",
            "  File \"<frozen runpy>\", line 287, in run_path\n",
            "  File \"<frozen runpy>\", line 98, in _run_module_code\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/recipes/full_finetune_single_device.py\", line 807, in <module>\n",
            "    sys.exit(recipe_main())\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/config/_parse.py\", line 99, in wrapper\n",
            "    sys.exit(recipe_main(conf))\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/recipes/full_finetune_single_device.py\", line 801, in recipe_main\n",
            "    recipe.setup(cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/recipes/full_finetune_single_device.py\", line 260, in setup\n",
            "    ckpt_dict = self.load_checkpoint(cfg.checkpointer)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/recipes/full_finetune_single_device.py\", line 200, in load_checkpoint\n",
            "    self._checkpointer = config.instantiate(\n",
            "                         ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/config/_instantiate.py\", line 112, in instantiate\n",
            "    return _instantiate_node(OmegaConf.to_object(config), *args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/config/_instantiate.py\", line 33, in _instantiate_node\n",
            "    return _create_component(_component_, args, kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/config/_instantiate.py\", line 22, in _create_component\n",
            "    return _component_(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchtune/training/checkpointing/_checkpointer.py\", line 440, in __init__\n",
            "    Path.joinpath(self._checkpoint_dir, \"config.json\").read_text()\n",
            "  File \"/usr/lib/python3.12/pathlib.py\", line 1027, in read_text\n",
            "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/pathlib.py\", line 1013, in open\n",
            "    return io.open(self, mode, buffering, encoding, errors, newline)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Llama-3.2-1B-Instruct/config.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "ds = load_dataset(\n",
        "  'bitext/Bitext-customer-support-llm-chatbot-training-dataset',\n",
        "  split=\"train\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVxgputBXFN0",
        "outputId": "9fe46fae-0df2-4f89-b74c-ebd7e09c878b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OipvSzQwf4fK",
        "outputId": "6c40e9fe-7f26-4619-d433-75f4a09e0fc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26872, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P6CtbxEfDDU",
        "outputId": "c4bccaa0-2292-46bd-b731-28d01641a168"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['flags', 'instruction', 'category', 'intent', 'response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXfwqIX2c-dn",
        "outputId": "13aa355d-6da3-4826-b21b-e496d94cec75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category': 'ORDER',\n",
            " 'flags': 'B',\n",
            " 'instruction': 'question about cancelling order {{Order Number}}',\n",
            " 'intent': 'cancel_order',\n",
            " 'response': \"I've understood you have a question regarding canceling order \"\n",
            "             \"{{Order Number}}, and I'm here to provide you with the \"\n",
            "             'information you need. Please go ahead and ask your question, and '\n",
            "             \"I'll do my best to assist you.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POaTaWutfHQc",
        "outputId": "79c3742f-04a7-4259-fc73-d40d73fac294"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BQZ',\n",
              " 'instruction': 'i have a question about cancelling oorder {{Order Number}}',\n",
              " 'category': 'ORDER',\n",
              " 'intent': 'cancel_order',\n",
              " 'response': \"I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_thousand_points = ds[:1000]\n",
        "ds = Dataset.from_dict(first_thousand_points)"
      ],
      "metadata": {
        "id": "6QbgrAaefaRz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzdWElGyisov",
        "outputId": "594a764e-7194-4f51-e9c3-a29b700a78cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_example(row):\n",
        "  row['conversation'] = f\"Query: {row['instruction']}\\nResponse: {row['response']}\"\n",
        "  return row"
      ],
      "metadata": {
        "id": "OGlWpx2wi7Fv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(merge_example)\n",
        "print(ds[0]['conversation'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "fc553e61f3f646bbb07e283015153519",
            "e1803ca8d0d6466ead2f97eedbed3cf8",
            "6e2f30dc29984ca8be6e5c9ed717d0bc",
            "a98d23652e1b4bf3a18aa1a02cf12534",
            "0b3f8eec26634792857e2468cda33af1",
            "3ae11800ddca4802b6b28fdf0c68f7ef",
            "c3e4c9b9be2441b0bec7d2486d9ba523",
            "788de093a4da4da98b9518b673a99b65",
            "b908a568101f44aba10fc8834b03fb37",
            "af9d3d3a5b4042c0914ebc97feb31b39",
            "b3e1bb89d2d442e3a1b180c00821f6d5"
          ]
        },
        "id": "qHbgOcXUjE7_",
        "outputId": "f7fa25b9-c8dc-4fc4-9b31-7b2a2e362c57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc553e61f3f646bbb07e283015153519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: question about cancelling order {{Order Number}}\n",
            "Response: I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3_JUvvSjFQe",
        "outputId": "a3f6f1fd-091f-4bdf-afab-4973db051aca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4ieS38TjIqn",
        "outputId": "a92b2a3a-4eee-49af-86bc-9055eec8d0d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BQZ',\n",
              " 'instruction': 'i have a question about cancelling oorder {{Order Number}}',\n",
              " 'category': 'ORDER',\n",
              " 'intent': 'cancel_order',\n",
              " 'response': \"I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\",\n",
              " 'conversation': \"Query: i have a question about cancelling oorder {{Order Number}}\\nResponse: I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.save_to_disk(\"preprocessed_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "420aa20a66ff438183ba9f951d975f10",
            "1881fdde96e947bbb9acc96bf9640d56",
            "258c173589d5446c88cbbbc138a5547b",
            "02a5b5ba92f345e6b89c399d431c7803",
            "f6389900233f4072856b776828199aee",
            "6d739726c169449295624a3bac536d13",
            "0400930ad2a444dda17b63143499e780",
            "e51fe3a35b624b73baa9a5b13da84edc",
            "e531bcd973804ca6897240d291ba74e0",
            "29b60355747d4fb495679faeb3a4791f",
            "36d7cf37fb0d43d0b170a6e8fe9c97d6"
          ]
        },
        "id": "NFFbE9DUjKBm",
        "outputId": "b5a9e096-9377-4bed-ea1e-720f90032910"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "420aa20a66ff438183ba9f951d975f10"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "ds_preprocessed = load_from_disk(\"preprocessed_dataset\")"
      ],
      "metadata": {
        "id": "UQ5ghE66jtCX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWOa6jHtkEBG"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}