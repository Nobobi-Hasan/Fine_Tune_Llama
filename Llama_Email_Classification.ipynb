{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv/XNXyBkNrHgKu1RXZ9oC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nobobi-Hasan/Fine_Tune_Llama/blob/main/Llama_Email_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DataCamp Project**"
      ],
      "metadata": {
        "id": "w4SFTHWESu-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every day, professionals wade through hundreds of emails, from urgent client requests to promotional offers. It's like trying to find important messages in a digital ocean. But AI can help you stay afloat by automatically sorting emails to highlight what matters most.\n",
        "\n",
        "You've been asked to build an intelligent email assistant using Llama, to help users automatically classify their incoming emails. Your system will identify which emails need immediate attention, which are regular updates, and which are promotions that can wait or be archived.\n",
        "\n",
        "### The Data\n",
        "You'll work with a dataset of various email examples, ranging from urgent business communications to promotional offers. Here's a peek at what you'll be working with:\n",
        "\n",
        "### email_categories_data.csv\n",
        "\n",
        " Column | Description |\n",
        "|--------|-------------|\n",
        "| email_id | A unique identifier for each email in the dataset. |\n",
        "| email_content | The full email text including subject line and body. Each email follows a format of \"Subject\" followed by the message content on a new line. |\n",
        "| expected_category | The correct classification of the email: `Priority`, `Updates`, or `Promotions`. This will be used to validate your model's performance. |\n"
      ],
      "metadata": {
        "id": "ObT1yA7NQfoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJvOFZT8QP_P"
      },
      "outputs": [],
      "source": [
        "# Run the following cells first\n",
        "# Install necessary packages, then import the model running the cell below\n",
        "!pip install llama-cpp-python==0.2.82 -q -q -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT *\n",
        "FROM 'models.csv'\n",
        "LIMIT 5"
      ],
      "metadata": {
        "id": "RU7V4Sb8Qr5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "BykemdIzQr7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the email dataset\n",
        "emails_df = pd.read_csv('data/email_categories_data.csv')\n",
        "# Display the first few rows of our dataset\n",
        "print(\"Preview of our email dataset:\")\n",
        "emails_df.head(2)"
      ],
      "metadata": {
        "id": "kYj59BNvQr9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model path\n",
        "model_path = \"/files-integrations/files/c9696c24-44f3-45f7-8ccd-4b9b046e7e53/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\""
      ],
      "metadata": {
        "id": "bIJRoG0GQsAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in emails_df['email_content']:\n",
        "    print(len(c))"
      ],
      "metadata": {
        "id": "k2wZse6aQsDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Llama model\n",
        "# We set n_gpu_layers=0 to run the model on the CPU, ensuring portability\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=128, # Context window size\n",
        "    n_gpu_layers=0, # Number of layers to offload to GPU\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "CjJ5DResQsE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt string\n",
        "prompt = \"\"\"\n",
        "You are an expert email classification system. Your task is to read an email and classify it into one of the following three categories: \"Priority\", \"Updates\", or \"Promotions\".\n",
        "\n",
        "Only output the single category name. Do not include any other text, explanation, or punctuation.\n",
        "\n",
        "Email: {email_content}\n",
        "\n",
        "Category:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oTKToLvwQsG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the content of the first two emails\n",
        "email1 = emails_df.loc[0, 'email_content']\n",
        "email2 = emails_df.loc[1, 'email_content']"
      ],
      "metadata": {
        "id": "8VnV-z3IQsIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test on the First Email ---\n",
        "# Format the prompt with the first email content\n",
        "prompt1 = prompt.format(email_content=email1)\n",
        "\n",
        "# Generate the classification result\n",
        "output1 = llm.create_completion(\n",
        "    prompt=prompt1,\n",
        "    max_tokens=20, # Only need a few tokens for the category name\n",
        "    stop=[\"\\n\"],   # Stop generation at the first newline character\n",
        "    temperature=0.0 # Set temperature to 0 for deterministic classification\n",
        ")\n",
        "\n",
        "# Extract and clean the result\n",
        "result1 = output1['choices'][0]['text'].strip()\n",
        "print(f\"Classification for Email 1: {result1}\")"
      ],
      "metadata": {
        "id": "0ltHgENUQsLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test on the Second Email ---\n",
        "# Format the prompt with the second email content\n",
        "prompt2 = prompt.format(email_content=email2)\n",
        "\n",
        "# Generate the classification result\n",
        "output2 = llm.create_completion(\n",
        "    prompt=prompt2,\n",
        "    max_tokens=20,\n",
        "    stop=[\"\\n\"],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# Extract and clean the result\n",
        "result2 = output2['choices'][0]['text'].strip()\n",
        "print(f\"Classification for Email 2: {result2}\")"
      ],
      "metadata": {
        "id": "7nTusrkhQ-AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final Variables ---\")\n",
        "print(f\"Prompt (Template):\\n{prompt}\")\n",
        "print(f\"Result 1 (Classification for Email 1):\\n{result1}\")\n",
        "print(f\"Result 2 (Classification for Email 2):\\n{result2}\")"
      ],
      "metadata": {
        "id": "5EBvO8jsQ-DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlb1_3jCQ-Fr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}